{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdd8bf1",
   "metadata": {},
   "source": [
    "# 日本語版 GPT Quick Start\n",
    "\n",
    "[rinnaの日本語特化GPTモデルを触ってみた - 雲のメモ帳](https://www.cloudnotes.tech/entry/rinna_gpt_jp#%E5%8B%95%E4%BD%9C%E7%A2%BA%E8%AA%8D)\n",
    "の真似事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24eb284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ae5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "333c9bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94048a8e35642a9838f88c59e6b4af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d47ac68f1d43e6b355741a9ffcda51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/153 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40b63ed473f45e1ba8901db9c025913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/283 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f8b8057bbc4b39ba1684a27aa2276a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e54973a593848c287610c0a3ef0d755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt-1b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt-1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d284754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5931cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text):\n",
    "    token_ids = tokenizer.encode(text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            token_ids.to(model.device),\n",
    "            max_length=100,\n",
    "            min_length=100,\n",
    "            do_sample=True,\n",
    "            top_k=500,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            bod_word_ids=[[tokenizer.unk_token_id]]\n",
    "        )\n",
    "        \n",
    "        output = tokenizer.decode(output_ids.tolist()[0])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3abe1502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今日は日曜日です。明日は、もう12月です。一年早いなあ。この一年、たくさんの方とお会いすることができました。今年もありがとうございました。明日も、おしゃべりにきてくださいね。お待ちしています。 写真は、今日仕入れにいったものです。今は、バジルとパセリがたくさんなっています。お味噌の袋にも、たくさんバジルとパセリが入っているので、最近は味噌汁の中にバジルを入れて飲むのがお気に入り。バジルソースになります。パセリも、最近たくさんバジル'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"今日は日曜日です。明日は、\"\n",
    "generate_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8731c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今日の会議は、時間がかかりました。明日からは、新しい担当者の準備の時間が少なくてすみそうです。そして、来週から、いろいろな相談が始まるはずでした。しかし、もうその新しい担当者は、東京に出てしまいました。また、担当者は変わるかもしれません。新しい担当者の仕事は、責任重大です。それを断ることも難しい。いつも後手後手になってしまいます。新しい担当者は、あまり頼りにはできませんが、私に足りない所を補ってくれそうな人です。とにかく、明日は、私が話しをうまく引き出して'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"今日の会議は、時間がかかりました。明日からは、\"\n",
    "generate_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7af094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
